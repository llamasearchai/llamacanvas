{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LlamaCanvas Documentation","text":"<p>Welcome to the LlamaCanvas documentation. LlamaCanvas is an advanced AI-driven multi-modal generation platform with Claude API integration.</p>"},{"location":"#what-is-llamacanvas","title":"What is LlamaCanvas?","text":"<p>LlamaCanvas provides tools for creating and transforming visual content using state-of-the-art AI models. It integrates with Claude API and offers a comprehensive platform for image and video generation, manipulation, and enhancement.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Image Generation: Create images from text prompts using Stable Diffusion or Claude</li> <li>Image Enhancement: Upscale, denoise, and improve images with AI</li> <li>Style Transfer: Apply artistic styles to existing images</li> <li>Video Processing: Generate and manipulate video content</li> <li>Extensible Agent System: Integrate different AI models with a unified interface</li> <li>Multiple Interfaces: Web UI, CLI, and Python API options</li> <li>Claude Integration: Leverage Anthropic's Claude for multi-modal generation</li> <li>Pipeline Architecture: Chain operations for complex transformations</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># Basic installation\npip install llama-canvas\n\n# With all features\npip install llama-canvas[full]\n</code></pre> <p>For more detailed installation options, see the Installation Guide.</p>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#generate-an-image-from-text","title":"Generate an image from text","text":"<pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas(width=512, height=512)\nimage = canvas.generate_from_text(\n    \"A serene landscape with mountains and a lake at sunset\"\n)\nimage.save(\"landscape.png\")\n</code></pre>"},{"location":"#apply-style-transfer","title":"Apply style transfer","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\noriginal = Image.load(\"input.png\")\nstyled = canvas.apply_style(original, \"Van Gogh\")\nstyled.save(\"styled_output.png\")\n</code></pre> <p>For more examples, check out the Quick Start Guide or browse the Examples section.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<ul> <li>User Guide: Detailed explanations of LlamaCanvas concepts and features</li> <li>API Reference: Comprehensive documentation of the Python API</li> <li>Examples: Sample code and usage patterns</li> <li>Contributing: Guidelines for contributing to LlamaCanvas</li> </ul>"},{"location":"#support-and-community","title":"Support and Community","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> <li>GitHub Discussions: Ask questions and share ideas</li> </ul>"},{"location":"#license","title":"License","text":"<p>LlamaCanvas is released under the MIT License. See the LICENSE file for details. </p>"},{"location":"api_reference/canvas/","title":"Canvas API Reference","text":"<p>The <code>Canvas</code> class is the central component of LlamaCanvas, providing methods for image and video generation, manipulation, and enhancement.</p>"},{"location":"api_reference/canvas/#canvas-class","title":"Canvas Class","text":"<pre><code>from llama_canvas.core.canvas import Canvas\n</code></pre>"},{"location":"api_reference/canvas/#constructor","title":"Constructor","text":"<pre><code>Canvas(width=512, height=512, agent=None, config=None)\n</code></pre> <p>Creates a new Canvas instance.</p>"},{"location":"api_reference/canvas/#parameters","title":"Parameters","text":"<ul> <li>width (<code>int</code>, optional): The default width for generated images. Defaults to 512.</li> <li>height (<code>int</code>, optional): The default height for generated images. Defaults to 512.</li> <li>agent (<code>Agent</code>, optional): The AI agent to use for generation. If not provided, a default agent will be used.</li> <li>config (<code>dict</code>, optional): Configuration options for the canvas.</li> </ul>"},{"location":"api_reference/canvas/#returns","title":"Returns","text":"<p>A new <code>Canvas</code> instance.</p>"},{"location":"api_reference/canvas/#example","title":"Example","text":"<pre><code>from llama_canvas.core.canvas import Canvas\n\n# Create a canvas with default settings\ncanvas = Canvas()\n\n# Create a canvas with custom dimensions\ncanvas = Canvas(width=1024, height=768)\n\n# Create a canvas with a specific agent\nfrom llama_canvas.utils.claude import ClaudeAgent\nclaude_agent = ClaudeAgent(api_key=\"your-api-key\")\ncanvas = Canvas(agent=claude_agent)\n</code></pre>"},{"location":"api_reference/canvas/#methods","title":"Methods","text":""},{"location":"api_reference/canvas/#generate_from_text","title":"generate_from_text","text":"<pre><code>generate_from_text(prompt, width=None, height=None, options=None)\n</code></pre> <p>Generates an image from a text prompt.</p>"},{"location":"api_reference/canvas/#parameters_1","title":"Parameters","text":"<ul> <li>prompt (<code>str</code>): The text prompt describing the image to generate.</li> <li>width (<code>int</code>, optional): The width of the generated image. If not provided, uses the canvas default.</li> <li>height (<code>int</code>, optional): The height of the generated image. If not provided, uses the canvas default.</li> <li>options (<code>dict</code>, optional): Additional options for the generation process.</li> </ul>"},{"location":"api_reference/canvas/#returns_1","title":"Returns","text":"<p>An <code>Image</code> object representing the generated image.</p>"},{"location":"api_reference/canvas/#example_1","title":"Example","text":"<pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas()\nimage = canvas.generate_from_text(\n    \"A serene landscape with mountains and a lake at sunset\"\n)\nimage.save(\"landscape.png\")\n</code></pre>"},{"location":"api_reference/canvas/#apply_style","title":"apply_style","text":"<pre><code>apply_style(image, style, strength=1.0, options=None)\n</code></pre> <p>Applies a style to an image.</p>"},{"location":"api_reference/canvas/#parameters_2","title":"Parameters","text":"<ul> <li>image (<code>Image</code>): The image to apply the style to.</li> <li>style (<code>str</code>): The name of the style to apply, or a text description of the style.</li> <li>strength (<code>float</code>, optional): The strength of the style application, between 0.0 and 1.0. Defaults to 1.0.</li> <li>options (<code>dict</code>, optional): Additional options for the style application.</li> </ul>"},{"location":"api_reference/canvas/#returns_2","title":"Returns","text":"<p>An <code>Image</code> object representing the styled image.</p>"},{"location":"api_reference/canvas/#example_2","title":"Example","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\noriginal = Image.load(\"input.png\")\nstyled = canvas.apply_style(original, \"Van Gogh\")\nstyled.save(\"styled_output.png\")\n</code></pre>"},{"location":"api_reference/canvas/#enhance","title":"enhance","text":"<pre><code>enhance(image, scale=1.0, denoise=False, sharpen=False, options=None)\n</code></pre> <p>Enhances an image with AI-powered upscaling, denoising, and sharpening.</p>"},{"location":"api_reference/canvas/#parameters_3","title":"Parameters","text":"<ul> <li>image (<code>Image</code>): The image to enhance.</li> <li>scale (<code>float</code>, optional): The factor by which to scale the image. Defaults to 1.0.</li> <li>denoise (<code>bool</code>, optional): Whether to apply denoising. Defaults to False.</li> <li>sharpen (<code>bool</code>, optional): Whether to apply sharpening. Defaults to False.</li> <li>options (<code>dict</code>, optional): Additional options for the enhancement process.</li> </ul>"},{"location":"api_reference/canvas/#returns_3","title":"Returns","text":"<p>An <code>Image</code> object representing the enhanced image.</p>"},{"location":"api_reference/canvas/#example_3","title":"Example","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\noriginal = Image.load(\"input.png\")\nenhanced = canvas.enhance(original, scale=2.0, denoise=True, sharpen=True)\nenhanced.save(\"enhanced_output.png\")\n</code></pre>"},{"location":"api_reference/canvas/#create_video_from_prompts","title":"create_video_from_prompts","text":"<pre><code>create_video_from_prompts(prompts, duration=10, fps=30, transition=\"fade\", options=None)\n</code></pre> <p>Creates a video from a sequence of text prompts.</p>"},{"location":"api_reference/canvas/#parameters_4","title":"Parameters","text":"<ul> <li>prompts (<code>list[str]</code>): A list of text prompts to generate images from.</li> <li>duration (<code>float</code>, optional): The duration of the video in seconds. Defaults to 10.</li> <li>fps (<code>int</code>, optional): The frames per second of the video. Defaults to 30.</li> <li>transition (<code>str</code>, optional): The type of transition between images. Options include \"fade\", \"dissolve\", \"slide\", \"zoom\". Defaults to \"fade\".</li> <li>options (<code>dict</code>, optional): Additional options for the video creation process.</li> </ul>"},{"location":"api_reference/canvas/#returns_4","title":"Returns","text":"<p>A <code>Video</code> object representing the created video.</p>"},{"location":"api_reference/canvas/#example_4","title":"Example","text":"<pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas()\nprompts = [\n    \"A serene landscape with mountains at dawn\",\n    \"A serene landscape with mountains at noon\",\n    \"A serene landscape with mountains at sunset\",\n    \"A serene landscape with mountains at night\"\n]\nvideo = canvas.create_video_from_prompts(prompts, duration=10, fps=30, transition=\"fade\")\nvideo.save(\"landscape_timelapse.mp4\")\n</code></pre>"},{"location":"api_reference/canvas/#create_video_from_images","title":"create_video_from_images","text":"<pre><code>create_video_from_images(images, duration=10, fps=30, transition=\"fade\", options=None)\n</code></pre> <p>Creates a video from a sequence of images.</p>"},{"location":"api_reference/canvas/#parameters_5","title":"Parameters","text":"<ul> <li>images (<code>list[Image]</code>): A list of Image objects to create a video from.</li> <li>duration (<code>float</code>, optional): The duration of the video in seconds. Defaults to 10.</li> <li>fps (<code>int</code>, optional): The frames per second of the video. Defaults to 30.</li> <li>transition (<code>str</code>, optional): The type of transition between images. Options include \"fade\", \"dissolve\", \"slide\", \"zoom\". Defaults to \"fade\".</li> <li>options (<code>dict</code>, optional): Additional options for the video creation process.</li> </ul>"},{"location":"api_reference/canvas/#returns_5","title":"Returns","text":"<p>A <code>Video</code> object representing the created video.</p>"},{"location":"api_reference/canvas/#example_5","title":"Example","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\nimages = [\n    Image.load(\"dawn.png\"),\n    Image.load(\"noon.png\"),\n    Image.load(\"sunset.png\"),\n    Image.load(\"night.png\")\n]\nvideo = canvas.create_video_from_images(images, duration=10, fps=30, transition=\"fade\")\nvideo.save(\"landscape_timelapse.mp4\")\n</code></pre>"},{"location":"api_reference/canvas/#usage-with-different-agents","title":"Usage with Different Agents","text":""},{"location":"api_reference/canvas/#claude-agent","title":"Claude Agent","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.utils.claude import ClaudeAgent\n\nclaude_agent = ClaudeAgent(api_key=\"your-api-key\", model=\"claude-3-opus-20240229\")\ncanvas = Canvas(agent=claude_agent)\n\nimage = canvas.generate_from_text(\"A robot artist painting a landscape\")\nimage.save(\"claude_generated.png\")\n</code></pre>"},{"location":"api_reference/canvas/#stable-diffusion-agent","title":"Stable Diffusion Agent","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.utils.stable_diffusion import StableDiffusionAgent\n\nsd_agent = StableDiffusionAgent(model=\"stabilityai/stable-diffusion-xl-base-1.0\")\ncanvas = Canvas(agent=sd_agent)\n\nimage = canvas.generate_from_text(\"A robot artist painting a landscape\")\nimage.save(\"sd_generated.png\")\n</code></pre>"},{"location":"api_reference/image/","title":"Image API Reference","text":"<p>The <code>Image</code> class in LlamaCanvas provides a comprehensive set of methods for working with images. This class handles loading, saving, manipulating, and analyzing image data.</p>"},{"location":"api_reference/image/#class-overview","title":"Class Overview","text":"<pre><code>from llama_canvas.core.image import Image\n</code></pre>"},{"location":"api_reference/image/#creating-and-loading-images","title":"Creating and Loading Images","text":""},{"location":"api_reference/image/#static-methods","title":"Static Methods","text":""},{"location":"api_reference/image/#imagecreate","title":"<code>Image.create()</code>","text":"<p>Creates a new blank image with the specified dimensions and background color.</p> <pre><code>@staticmethod\ndef create(width: int, \n           height: int, \n           background_color: Union[str, Tuple[int, int, int, int]] = \"transparent\") -&gt; \"Image\":\n    \"\"\"\n    Create a new blank image.\n\n    Args:\n        width: Width of the image in pixels\n        height: Height of the image in pixels\n        background_color: Color to fill the image with. Can be a string name ('transparent', 'white', 'black', etc.) \n                          or an RGBA tuple (0-255 for each channel)\n\n    Returns:\n        A new Image instance\n    \"\"\"\n</code></pre> <p>Example: <pre><code># Create a 512x512 blank white image\nwhite_image = Image.create(512, 512, \"white\")\n\n# Create a 1024x768 image with a semi-transparent blue background\nblue_image = Image.create(1024, 768, (0, 0, 255, 128))\n</code></pre></p>"},{"location":"api_reference/image/#imageload","title":"<code>Image.load()</code>","text":"<p>Loads an image from a file or URL.</p> <pre><code>@staticmethod\ndef load(source: Union[str, Path, bytes]) -&gt; \"Image\":\n    \"\"\"\n    Load an image from a file path, URL, or bytes.\n\n    Args:\n        source: File path, URL, or bytes containing image data\n\n    Returns:\n        An Image instance with the loaded image\n\n    Raises:\n        ValueError: If the image cannot be loaded\n    \"\"\"\n</code></pre> <p>Example: <pre><code># Load from file\nimg1 = Image.load(\"path/to/image.png\")\n\n# Load from URL\nimg2 = Image.load(\"https://example.com/image.jpg\")\n\n# Load from bytes\nwith open(\"image.png\", \"rb\") as f:\n    img3 = Image.load(f.read())\n</code></pre></p>"},{"location":"api_reference/image/#imagefrom_array","title":"<code>Image.from_array()</code>","text":"<p>Creates an image from a NumPy array.</p> <pre><code>@staticmethod\ndef from_array(array: np.ndarray) -&gt; \"Image\":\n    \"\"\"\n    Create an image from a NumPy array.\n\n    Args:\n        array: NumPy array in the format (height, width, channels)\n              where channels is 1 (grayscale), 3 (RGB), or 4 (RGBA)\n\n    Returns:\n        An Image instance containing the array data\n\n    Raises:\n        ValueError: If the array format is invalid\n    \"\"\"\n</code></pre> <p>Example: <pre><code>import numpy as np\n\n# Create a red square image\nred_array = np.zeros((100, 100, 3), dtype=np.uint8)\nred_array[:, :, 0] = 255  # Set red channel to maximum\nimg = Image.from_array(red_array)\n</code></pre></p>"},{"location":"api_reference/image/#basic-properties-and-methods","title":"Basic Properties and Methods","text":""},{"location":"api_reference/image/#properties","title":"Properties","text":"<ul> <li><code>width</code>: Width of the image in pixels</li> <li><code>height</code>: Height of the image in pixels</li> <li><code>size</code>: Tuple of (width, height)</li> <li><code>aspect_ratio</code>: Width divided by height</li> <li><code>channels</code>: Number of color channels (1 for grayscale, 3 for RGB, 4 for RGBA)</li> <li><code>mode</code>: Color mode ('L' for grayscale, 'RGB', 'RGBA', etc.)</li> <li><code>format</code>: Image format if known ('PNG', 'JPEG', etc.)</li> </ul>"},{"location":"api_reference/image/#methods","title":"Methods","text":""},{"location":"api_reference/image/#save","title":"<code>save()</code>","text":"<p>Saves the image to a file.</p> <pre><code>def save(self, \n         path: Union[str, Path], \n         format: Optional[str] = None, \n         quality: int = 95) -&gt; None:\n    \"\"\"\n    Save the image to a file.\n\n    Args:\n        path: Path where the image should be saved\n        format: Image format ('PNG', 'JPEG', 'WEBP', etc.). If None, inferred from file extension\n        quality: Quality for lossy formats (0-100)\n\n    Raises:\n        ValueError: If the image cannot be saved or the format is unsupported\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#copy","title":"<code>copy()</code>","text":"<p>Creates a deep copy of the image.</p> <pre><code>def copy(self) -&gt; \"Image\":\n    \"\"\"\n    Create a deep copy of the image.\n\n    Returns:\n        A new Image instance with the same content\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#to_array","title":"<code>to_array()</code>","text":"<p>Converts the image to a NumPy array.</p> <pre><code>def to_array(self) -&gt; np.ndarray:\n    \"\"\"\n    Convert the image to a NumPy array.\n\n    Returns:\n        NumPy array in the format (height, width, channels)\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#to_base64","title":"<code>to_base64()</code>","text":"<p>Converts the image to a base64-encoded string.</p> <pre><code>def to_base64(self, \n              format: str = \"PNG\") -&gt; str:\n    \"\"\"\n    Convert the image to a base64-encoded string.\n\n    Args:\n        format: Image format to use ('PNG', 'JPEG', etc.)\n\n    Returns:\n        Base64-encoded string\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#to_bytes","title":"<code>to_bytes()</code>","text":"<p>Converts the image to bytes.</p> <pre><code>def to_bytes(self, \n             format: str = \"PNG\", \n             quality: int = 95) -&gt; bytes:\n    \"\"\"\n    Convert the image to bytes.\n\n    Args:\n        format: Image format to use ('PNG', 'JPEG', etc.)\n        quality: Quality for lossy formats (0-100)\n\n    Returns:\n        Image data as bytes\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#transformation-methods","title":"Transformation Methods","text":""},{"location":"api_reference/image/#resize","title":"<code>resize()</code>","text":"<p>Resizes the image to the specified dimensions.</p> <pre><code>def resize(self, \n           width: Optional[int] = None, \n           height: Optional[int] = None, \n           method: str = \"lanczos\") -&gt; \"Image\":\n    \"\"\"\n    Resize the image.\n\n    Args:\n        width: New width in pixels. If None, calculated from height to maintain aspect ratio\n        height: New height in pixels. If None, calculated from width to maintain aspect ratio\n        method: Resampling method ('nearest', 'box', 'bilinear', 'hamming', 'bicubic', 'lanczos')\n\n    Returns:\n        A new resized Image instance\n\n    Raises:\n        ValueError: If both width and height are None\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#crop","title":"<code>crop()</code>","text":"<p>Crops the image to the specified region.</p> <pre><code>def crop(self, \n         x: int, \n         y: int, \n         width: int, \n         height: int) -&gt; \"Image\":\n    \"\"\"\n    Crop the image to the specified region.\n\n    Args:\n        x: X-coordinate of the top-left corner\n        y: Y-coordinate of the top-left corner\n        width: Width of the cropped region\n        height: Height of the cropped region\n\n    Returns:\n        A new cropped Image instance\n\n    Raises:\n        ValueError: If the crop region is outside the image bounds\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#rotate","title":"<code>rotate()</code>","text":"<p>Rotates the image by the specified angle.</p> <pre><code>def rotate(self, \n           angle: float, \n           expand: bool = False, \n           fill_color: Union[str, Tuple[int, int, int, int]] = \"transparent\") -&gt; \"Image\":\n    \"\"\"\n    Rotate the image by the specified angle.\n\n    Args:\n        angle: Rotation angle in degrees (counter-clockwise)\n        expand: Whether to expand the image to fit the rotated content\n        fill_color: Color to fill new areas with\n\n    Returns:\n        A new rotated Image instance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#flip","title":"<code>flip()</code>","text":"<p>Flips the image horizontally or vertically.</p> <pre><code>def flip(self, \n         direction: str = \"horizontal\") -&gt; \"Image\":\n    \"\"\"\n    Flip the image horizontally or vertically.\n\n    Args:\n        direction: Direction to flip ('horizontal' or 'vertical')\n\n    Returns:\n        A new flipped Image instance\n\n    Raises:\n        ValueError: If direction is not 'horizontal' or 'vertical'\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#color-operations","title":"Color Operations","text":""},{"location":"api_reference/image/#adjust_brightness","title":"<code>adjust_brightness()</code>","text":"<p>Adjusts the brightness of the image.</p> <pre><code>def adjust_brightness(self, \n                      factor: float) -&gt; \"Image\":\n    \"\"\"\n    Adjust the brightness of the image.\n\n    Args:\n        factor: Brightness adjustment factor (0.0 = black, 1.0 = original, &gt;1.0 = brighter)\n\n    Returns:\n        A new adjusted Image instance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#adjust_contrast","title":"<code>adjust_contrast()</code>","text":"<p>Adjusts the contrast of the image.</p> <pre><code>def adjust_contrast(self, \n                    factor: float) -&gt; \"Image\":\n    \"\"\"\n    Adjust the contrast of the image.\n\n    Args:\n        factor: Contrast adjustment factor (0.0 = gray, 1.0 = original, &gt;1.0 = more contrast)\n\n    Returns:\n        A new adjusted Image instance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#adjust_saturation","title":"<code>adjust_saturation()</code>","text":"<p>Adjusts the color saturation of the image.</p> <pre><code>def adjust_saturation(self, \n                      factor: float) -&gt; \"Image\":\n    \"\"\"\n    Adjust the color saturation of the image.\n\n    Args:\n        factor: Saturation adjustment factor (0.0 = grayscale, 1.0 = original, &gt;1.0 = more saturated)\n\n    Returns:\n        A new adjusted Image instance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#convert_mode","title":"<code>convert_mode()</code>","text":"<p>Converts the image to a different color mode.</p> <pre><code>def convert_mode(self, \n                 mode: str) -&gt; \"Image\":\n    \"\"\"\n    Convert the image to a different color mode.\n\n    Args:\n        mode: Target color mode ('L', 'RGB', 'RGBA', etc.)\n\n    Returns:\n        A new Image instance in the target mode\n\n    Raises:\n        ValueError: If the conversion is not supported\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#filters-and-effects","title":"Filters and Effects","text":""},{"location":"api_reference/image/#apply_filter","title":"<code>apply_filter()</code>","text":"<p>Applies a predefined filter to the image.</p> <pre><code>def apply_filter(self, \n                 filter_name: str, \n                 **parameters) -&gt; \"Image\":\n    \"\"\"\n    Apply a predefined filter to the image.\n\n    Args:\n        filter_name: Name of the filter to apply\n                    ('blur', 'sharpen', 'edge_enhance', 'emboss', 'find_edges', etc.)\n        **parameters: Filter-specific parameters\n\n    Returns:\n        A new filtered Image instance\n\n    Raises:\n        ValueError: If the filter is not supported\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#apply_effect","title":"<code>apply_effect()</code>","text":"<p>Applies a visual effect to the image.</p> <pre><code>def apply_effect(self, \n                 effect_name: str, \n                 intensity: float = 1.0, \n                 **parameters) -&gt; \"Image\":\n    \"\"\"\n    Apply a visual effect to the image.\n\n    Args:\n        effect_name: Name of the effect to apply\n                    ('vignette', 'grain', 'duotone', 'glitch', etc.)\n        intensity: Effect intensity (0.0 to 1.0)\n        **parameters: Effect-specific parameters\n\n    Returns:\n        A new Image instance with the effect applied\n\n    Raises:\n        ValueError: If the effect is not supported\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#drawing-and-compositing","title":"Drawing and Compositing","text":""},{"location":"api_reference/image/#draw_rectangle","title":"<code>draw_rectangle()</code>","text":"<p>Draws a rectangle on the image.</p> <pre><code>def draw_rectangle(self, \n                   x: int, \n                   y: int, \n                   width: int, \n                   height: int, \n                   color: Union[str, Tuple[int, int, int, int]], \n                   fill: bool = True, \n                   line_width: int = 1) -&gt; \"Image\":\n    \"\"\"\n    Draw a rectangle on the image.\n\n    Args:\n        x: X-coordinate of the top-left corner\n        y: Y-coordinate of the top-left corner\n        width: Width of the rectangle\n        height: Height of the rectangle\n        color: Color of the rectangle\n        fill: Whether to fill the rectangle\n        line_width: Width of the outline if not filled\n\n    Returns:\n        A new Image instance with the rectangle drawn\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#draw_ellipse","title":"<code>draw_ellipse()</code>","text":"<p>Draws an ellipse on the image.</p> <pre><code>def draw_ellipse(self, \n                 x: int, \n                 y: int, \n                 width: int, \n                 height: int, \n                 color: Union[str, Tuple[int, int, int, int]], \n                 fill: bool = True, \n                 line_width: int = 1) -&gt; \"Image\":\n    \"\"\"\n    Draw an ellipse on the image.\n\n    Args:\n        x: X-coordinate of the top-left corner of the bounding box\n        y: Y-coordinate of the top-left corner of the bounding box\n        width: Width of the bounding box\n        height: Height of the bounding box\n        color: Color of the ellipse\n        fill: Whether to fill the ellipse\n        line_width: Width of the outline if not filled\n\n    Returns:\n        A new Image instance with the ellipse drawn\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#draw_line","title":"<code>draw_line()</code>","text":"<p>Draws a line on the image.</p> <pre><code>def draw_line(self, \n              x1: int, \n              y1: int, \n              x2: int, \n              y2: int, \n              color: Union[str, Tuple[int, int, int, int]], \n              line_width: int = 1) -&gt; \"Image\":\n    \"\"\"\n    Draw a line on the image.\n\n    Args:\n        x1: X-coordinate of the start point\n        y1: Y-coordinate of the start point\n        x2: X-coordinate of the end point\n        y2: Y-coordinate of the end point\n        color: Color of the line\n        line_width: Width of the line\n\n    Returns:\n        A new Image instance with the line drawn\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#draw_text","title":"<code>draw_text()</code>","text":"<p>Draws text on the image.</p> <pre><code>def draw_text(self, \n              text: str, \n              x: int, \n              y: int, \n              font: Optional[str] = None, \n              font_size: int = 12, \n              color: Union[str, Tuple[int, int, int, int]] = \"black\", \n              align: str = \"left\") -&gt; \"Image\":\n    \"\"\"\n    Draw text on the image.\n\n    Args:\n        text: The text to draw\n        x: X-coordinate of the text position\n        y: Y-coordinate of the text position\n        font: Font to use (path to .ttf file or font name)\n        font_size: Size of the font in points\n        color: Color of the text\n        align: Text alignment ('left', 'center', 'right')\n\n    Returns:\n        A new Image instance with the text drawn\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#composite","title":"<code>composite()</code>","text":"<p>Composites another image onto this image.</p> <pre><code>def composite(self, \n              other: \"Image\", \n              x: int = 0, \n              y: int = 0, \n              opacity: float = 1.0, \n              blend_mode: str = \"normal\") -&gt; \"Image\":\n    \"\"\"\n    Composite another image onto this image.\n\n    Args:\n        other: The image to composite\n        x: X-coordinate of the top-left corner\n        y: Y-coordinate of the top-left corner\n        opacity: Opacity of the composited image (0.0 to 1.0)\n        blend_mode: Blending mode ('normal', 'multiply', 'screen', 'overlay', etc.)\n\n    Returns:\n        A new composited Image instance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#analysis-methods","title":"Analysis Methods","text":""},{"location":"api_reference/image/#get_dominant_colors","title":"<code>get_dominant_colors()</code>","text":"<p>Extracts the dominant colors from the image.</p> <pre><code>def get_dominant_colors(self, \n                        count: int = 5) -&gt; List[Tuple[int, int, int]]:\n    \"\"\"\n    Extract the dominant colors from the image.\n\n    Args:\n        count: Number of colors to extract\n\n    Returns:\n        List of RGB color tuples ordered by dominance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#get_average_color","title":"<code>get_average_color()</code>","text":"<p>Gets the average color of the image.</p> <pre><code>def get_average_color(self) -&gt; Tuple[int, int, int]:\n    \"\"\"\n    Get the average color of the image.\n\n    Returns:\n        RGB color tuple representing the average color\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#get_histogram","title":"<code>get_histogram()</code>","text":"<p>Gets the color histogram of the image.</p> <pre><code>def get_histogram(self, \n                  channel: Optional[int] = None) -&gt; np.ndarray:\n    \"\"\"\n    Get the color histogram of the image.\n\n    Args:\n        channel: Channel index to get histogram for (None for all channels)\n\n    Returns:\n        NumPy array containing the histogram data\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#advanced-methods","title":"Advanced Methods","text":""},{"location":"api_reference/image/#create_mask","title":"<code>create_mask()</code>","text":"<p>Creates a mask image.</p> <pre><code>@staticmethod\ndef create_mask(width: int, \n                height: int, \n                background: str = \"black\") -&gt; \"Image\":\n    \"\"\"\n    Create a mask image.\n\n    Args:\n        width: Width of the mask in pixels\n        height: Height of the mask in pixels\n        background: Background color ('black' for fully transparent, 'white' for fully opaque)\n\n    Returns:\n        A new Image instance with the mask\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#apply_mask","title":"<code>apply_mask()</code>","text":"<p>Applies a mask to the image.</p> <pre><code>def apply_mask(self, \n               mask: \"Image\") -&gt; \"Image\":\n    \"\"\"\n    Apply a mask to the image.\n\n    Args:\n        mask: Mask image (grayscale or alpha channel)\n              White areas in the mask keep the original image,\n              Black areas become transparent.\n\n    Returns:\n        A new masked Image instance\n\n    Raises:\n        ValueError: If the mask dimensions don't match the image\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#enhance","title":"<code>enhance()</code>","text":"<p>Enhances the image resolution using AI upscaling.</p> <pre><code>def enhance(self, \n            scale: float = 2.0, \n            method: str = \"super_resolution\") -&gt; \"Image\":\n    \"\"\"\n    Enhance the image resolution using AI upscaling.\n\n    Args:\n        scale: Scale factor for the enhancement\n        method: Enhancement method to use ('super_resolution', 'esrgan', etc.)\n\n    Returns:\n        A new enhanced Image instance\n    \"\"\"\n</code></pre>"},{"location":"api_reference/image/#example-usage","title":"Example Usage","text":"<pre><code>from llama_canvas.core.image import Image\n\n# Load an image\nimg = Image.load(\"input.jpg\")\n\n# Resize to 512x512\nresized = img.resize(512, 512)\n\n# Adjust brightness and contrast\nadjusted = resized.adjust_brightness(1.2).adjust_contrast(1.1)\n\n# Apply a filter\nfiltered = adjusted.apply_filter(\"edge_enhance\")\n\n# Draw some elements\nwith_rectangle = filtered.draw_rectangle(100, 100, 300, 200, \"red\", fill=False, line_width=3)\nwith_text = with_rectangle.draw_text(\"Enhanced Image\", 120, 120, font_size=24, color=\"white\")\n\n# Composite with another image\noverlay = Image.load(\"overlay.png\")\nresult = with_text.composite(overlay, x=200, y=200, opacity=0.7, blend_mode=\"overlay\")\n\n# Save the result\nresult.save(\"output.png\")\n\n# Get analysis\ndominant_colors = result.get_dominant_colors(count=3)\nprint(f\"Dominant colors: {dominant_colors}\")\n</code></pre>"},{"location":"user_guide/configuration/","title":"Configuration","text":"<p>LlamaCanvas offers multiple ways to configure the library to suit your needs. This page outlines the available configuration options and methods to apply them.</p>"},{"location":"user_guide/configuration/#configuration-methods","title":"Configuration Methods","text":"<p>LlamaCanvas provides several methods to configure the library, listed in order of precedence:</p> <ol> <li>Runtime Configuration: Parameters passed directly to methods and classes</li> <li>Environment Variables: System-wide environment variables</li> <li>Configuration Files: JSON configuration files in specific locations</li> <li>Default Values: Built-in fallback values</li> </ol>"},{"location":"user_guide/configuration/#configuration-file","title":"Configuration File","text":"<p>The primary way to configure LlamaCanvas is through a JSON configuration file located at <code>~/.llama_canvas/config.json</code>. Here's an example configuration file:</p> <pre><code>{\n  \"claude_api_key\": \"your-anthropic-api-key\",\n  \"default_claude_model\": \"claude-3-opus-20240229\",\n  \"default_image_width\": 512,\n  \"default_image_height\": 512,\n  \"default_output_dir\": \"~/llama_canvas_output\",\n  \"log_level\": \"INFO\",\n  \"agent_config\": {\n    \"claude\": {\n      \"timeout\": 60,\n      \"max_retries\": 3\n    },\n    \"stable_diffusion\": {\n      \"device\": \"cuda\",\n      \"precision\": \"fp16\"\n    }\n  }\n}\n</code></pre>"},{"location":"user_guide/configuration/#environment-variables","title":"Environment Variables","text":"<p>You can also configure LlamaCanvas using environment variables. These will override values in the configuration file. The following environment variables are supported:</p> Environment Variable Description Default Value <code>CLAUDE_API_KEY</code> Your Anthropic API key None <code>DEFAULT_CLAUDE_MODEL</code> Default Claude model to use \"claude-3-opus-20240229\" <code>DEFAULT_IMAGE_WIDTH</code> Default image width 512 <code>DEFAULT_IMAGE_HEIGHT</code> Default image height 512 <code>DEFAULT_OUTPUT_DIR</code> Default directory for saving outputs \"~/llama_canvas_output\" <code>LLAMA_CANVAS_LOG_LEVEL</code> Logging level \"INFO\" <p>Example of setting environment variables:</p> <pre><code>export CLAUDE_API_KEY=\"your-anthropic-api-key\"\nexport DEFAULT_CLAUDE_MODEL=\"claude-3-opus-20240229\"\n</code></pre>"},{"location":"user_guide/configuration/#configuration-options","title":"Configuration Options","text":"<p>Below is a detailed list of all configuration options available in LlamaCanvas:</p>"},{"location":"user_guide/configuration/#general-options","title":"General Options","text":"Option Description Default Value <code>default_image_width</code> Default width for generated images 512 <code>default_image_height</code> Default height for generated images 512 <code>default_output_dir</code> Default directory for saving outputs \"~/llama_canvas_output\" <code>log_level</code> Logging level \"INFO\""},{"location":"user_guide/configuration/#claude-integration","title":"Claude Integration","text":"Option Description Default Value <code>claude_api_key</code> Your Anthropic API key None <code>default_claude_model</code> Default Claude model to use \"claude-3-opus-20240229\" <code>claude_timeout</code> Timeout for Claude API requests (seconds) 60 <code>claude_max_retries</code> Maximum number of retries for Claude API requests 3"},{"location":"user_guide/configuration/#stable-diffusion-options","title":"Stable Diffusion Options","text":"Option Description Default Value <code>sd_device</code> Device to run Stable Diffusion on (\"cuda\", \"cpu\") \"cuda\" if available, else \"cpu\" <code>sd_precision</code> Precision for Stable Diffusion models (\"fp16\", \"fp32\") \"fp16\" <code>sd_default_model</code> Default Stable Diffusion model \"runwayml/stable-diffusion-v1-5\""},{"location":"user_guide/configuration/#web-ui-options","title":"Web UI Options","text":"Option Description Default Value <code>ui_host</code> Host address for the web UI \"127.0.0.1\" <code>ui_port</code> Port for the web UI 8080 <code>ui_theme</code> Theme for the web UI (\"light\", \"dark\") \"light\""},{"location":"user_guide/configuration/#programmatic-configuration","title":"Programmatic Configuration","text":"<p>You can also configure LlamaCanvas programmatically:</p> <pre><code>from llama_canvas.utils.config import Config\n\n# Load the default configuration\nconfig = Config()\n\n# Update specific values\nconfig.update({\n    \"default_image_width\": 1024,\n    \"default_image_height\": 1024,\n    \"claude_api_key\": \"your-anthropic-api-key\"\n})\n\n# Apply the configuration to the current session\nconfig.apply()\n</code></pre>"},{"location":"user_guide/configuration/#configuration-validation","title":"Configuration Validation","text":"<p>LlamaCanvas automatically validates your configuration when it's loaded. If there are any issues, warnings will be logged, and default values will be used where possible. If critical configuration options are missing (like API keys when needed), appropriate exceptions will be raised. </p>"},{"location":"user_guide/core_concepts/","title":"Core Concepts","text":"<p>This page introduces the fundamental concepts of LlamaCanvas that form the foundation of the library.</p>"},{"location":"user_guide/core_concepts/#canvas","title":"Canvas","text":"<p>The <code>Canvas</code> is the central concept in LlamaCanvas, representing a workspace where AI-powered image and video generation happens. The Canvas manages resources, coordinates between different agents, and provides a consistent interface for all operations.</p> <p>A Canvas can contain multiple layers, each potentially representing a different image or graphical element, and they can be manipulated together to create complex compositions.</p> <pre><code>from llama_canvas.core.canvas import Canvas\n\n# Create a canvas with specific dimensions\ncanvas = Canvas(width=1024, height=768)\n\n# Generate content on the canvas\ncanvas.generate_from_text(\"A beautiful mountain landscape at sunset\")\n</code></pre>"},{"location":"user_guide/core_concepts/#agents","title":"Agents","text":"<p>Agents in LlamaCanvas are specialized components that handle specific AI tasks. Each agent integrates with a different AI model or service to provide capabilities like:</p> <ul> <li>Text-to-image generation</li> <li>Image-to-image transformation</li> <li>Style transfer</li> <li>Image enhancement</li> <li>Video generation</li> </ul> <p>The most important agents in LlamaCanvas include:</p> <ul> <li><code>ClaudeAgent</code>: Integrates with Anthropic's Claude API for multi-modal generation</li> <li><code>StableDiffusionAgent</code>: Uses Stable Diffusion models for high-quality image generation</li> <li><code>EnhancementAgent</code>: Specializes in image enhancement and upscaling</li> <li><code>VideoAgent</code>: Handles video creation and processing</li> </ul> <p>Agents are typically managed by the Canvas, but can also be used directly for specialized workflows.</p> <pre><code>from llama_canvas.agents.claude import ClaudeAgent\n\n# Create a Claude agent with a specific model\nagent = ClaudeAgent(model=\"claude-3-opus-20240229\")\n\n# Use the agent directly\nresponse = agent.generate(prompt=\"Create an image of a futuristic city\")\n</code></pre>"},{"location":"user_guide/core_concepts/#images","title":"Images","text":"<p>The <code>Image</code> class represents image data within LlamaCanvas. It provides methods for manipulation, analysis, and export of images, including:</p> <ul> <li>Loading and saving images in various formats</li> <li>Basic transformations (resize, crop, rotate)</li> <li>Converting between different color spaces</li> <li>Applying filters and effects</li> <li>Extracting information from images (color palette, dominant colors)</li> </ul> <pre><code>from llama_canvas.core.image import Image\n\n# Load an image\nimg = Image.load(\"input.png\")\n\n# Resize the image\nresized = img.resize(width=512, height=512)\n\n# Apply a filter\nfiltered = resized.apply_filter(\"enhance_colors\")\n\n# Save the result\nfiltered.save(\"output.png\")\n</code></pre>"},{"location":"user_guide/core_concepts/#layers","title":"Layers","text":"<p>Layers allow for non-destructive editing and complex compositions. Each layer can contain an image or other graphical elements, and has properties like:</p> <ul> <li>Opacity</li> <li>Blend mode</li> <li>Position and transformation</li> <li>Masks and effects</li> </ul> <p>Layers can be added, removed, reordered, and modified within a Canvas.</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas(width=1024, height=768)\n\n# Add a background layer\nbackground = Image.load(\"background.png\")\ncanvas.add_layer(background, name=\"Background\")\n\n# Add a foreground element\nforeground = Image.load(\"foreground.png\")\ncanvas.add_layer(foreground, name=\"Foreground\", opacity=0.8, blend_mode=\"overlay\")\n\n# Adjust a layer\ncanvas.adjust_layer(\"Foreground\", position=(100, 100), scale=0.5)\n</code></pre>"},{"location":"user_guide/core_concepts/#styles","title":"Styles","text":"<p>Styles in LlamaCanvas define the visual appearance and characteristics that can be applied to images. Styles encompass:</p> <ul> <li>Artistic styles (like Impressionism, Cubism, etc.)</li> <li>Visual effects (like HDR, vignette, film grain)</li> <li>Color transformations (like sepia, black and white, color grade)</li> </ul> <p>Styles can be applied using various agents and methods.</p> <pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas()\nimage = canvas.load_image(\"input.png\")\n\n# Apply an artistic style\nstyled = canvas.apply_style(image, \"impressionist_painting\")\n\n# Apply a visual effect\nwith_effect = canvas.apply_effect(styled, \"film_grain\", intensity=0.5)\n</code></pre>"},{"location":"user_guide/core_concepts/#pipelines","title":"Pipelines","text":"<p>Pipelines allow you to chain together multiple operations into a reusable workflow. A pipeline can include:</p> <ul> <li>Image generation</li> <li>Transformations and effects</li> <li>Style applications</li> <li>Export operations</li> </ul> <p>Pipelines can be saved, loaded, and shared between projects.</p> <pre><code>from llama_canvas.core.pipeline import Pipeline\nfrom llama_canvas.core.canvas import Canvas\n\n# Create a pipeline\npipeline = Pipeline(\"landscape_generator\")\n\n# Add steps to the pipeline\npipeline.add_step(\"generate\", {\n    \"prompt\": \"A serene landscape with mountains and a lake at sunset\",\n    \"width\": 1024,\n    \"height\": 768\n})\npipeline.add_step(\"apply_style\", {\n    \"style\": \"oil_painting\"\n})\npipeline.add_step(\"enhance\", {\n    \"method\": \"super_resolution\",\n    \"scale\": 2\n})\n\n# Execute the pipeline\ncanvas = Canvas()\nresult = pipeline.execute(canvas)\nresult.save(\"landscape.png\")\n</code></pre>"},{"location":"user_guide/core_concepts/#projects","title":"Projects","text":"<p>A Project in LlamaCanvas represents a complete creative work, potentially containing multiple canvases, resources, and metadata. Projects can be saved to disk and loaded later to continue work.</p> <pre><code>from llama_canvas.core.project import Project\n\n# Create a new project\nproject = Project(\"my_artwork\")\n\n# Add a canvas to the project\ncanvas = project.create_canvas(width=1024, height=768)\n\n# Work with the canvas\ncanvas.generate_from_text(\"A beautiful mountain landscape at sunset\")\n\n# Save the project\nproject.save(\"/path/to/projects/my_artwork.llca\")\n</code></pre>"},{"location":"user_guide/core_concepts/#export-formats","title":"Export Formats","text":"<p>LlamaCanvas supports multiple export formats for sharing and using your creations:</p> <ul> <li>Common image formats (PNG, JPEG, WebP, TIFF)</li> <li>Video formats (MP4, GIF)</li> <li>Vector formats (SVG)</li> <li>Project format (.llca) for saving the complete project state</li> </ul> <p>Each format has specific options for quality, compression, and metadata.</p> <pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas()\n# ... create content on the canvas ...\n\n# Export in different formats\ncanvas.export(\"output.png\", format=\"png\")\ncanvas.export(\"output.jpg\", format=\"jpeg\", quality=95)\ncanvas.export(\"output.gif\", format=\"gif\", fps=10)\n</code></pre> <p>Understanding these core concepts will help you navigate the LlamaCanvas library and build powerful image and video generation workflows. </p>"},{"location":"user_guide/image_generation/","title":"Image Generation","text":"<p>LlamaCanvas provides multiple methods for generating images using AI models. This guide covers the various techniques available for creating images from text prompts or other inputs.</p>"},{"location":"user_guide/image_generation/#text-to-image-generation","title":"Text-to-Image Generation","text":"<p>The most common way to generate images with LlamaCanvas is from text descriptions. LlamaCanvas supports multiple AI models for this purpose, including Claude and Stable Diffusion.</p>"},{"location":"user_guide/image_generation/#using-claude-for-image-generation","title":"Using Claude for Image Generation","text":"<p>Claude's multimodal capabilities allow it to generate high-quality images from text descriptions:</p> <pre><code>from llama_canvas.core.canvas import Canvas\n\n# Create a canvas\ncanvas = Canvas()\n\n# Generate an image using Claude\nimage = canvas.generate_from_text(\n    prompt=\"A photorealistic image of a futuristic city with flying cars and neon lights\",\n    model=\"claude-3-opus-20240229\",  # Optional, uses default model if not specified\n    width=1024,\n    height=1024\n)\n\n# Save the generated image\nimage.save(\"futuristic_city.png\")\n</code></pre> <p>Using the command line interface:</p> <pre><code>llama-canvas generate \"A photorealistic image of a futuristic city with flying cars and neon lights\" \\\n    --model claude-3-opus-20240229 \\\n    --width 1024 \\\n    --height 1024 \\\n    --output futuristic_city.png\n</code></pre>"},{"location":"user_guide/image_generation/#using-stable-diffusion","title":"Using Stable Diffusion","text":"<p>For more control over the generation process, LlamaCanvas also supports Stable Diffusion:</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.agents.stable_diffusion import StableDiffusionAgent\n\n# Create a canvas\ncanvas = Canvas()\n\n# Generate an image using Stable Diffusion\nimage = canvas.generate_from_text(\n    prompt=\"A mystical forest with glowing mushrooms and fairy lights\",\n    agent=\"stable_diffusion\",\n    model=\"runwayml/stable-diffusion-v1-5\",  # Optional, uses default model if not specified\n    width=512,\n    height=512,\n    params={\n        \"num_inference_steps\": 50,\n        \"guidance_scale\": 7.5,\n        \"negative_prompt\": \"blurry, low quality, distorted\"\n    }\n)\n\n# Save the generated image\nimage.save(\"mystical_forest.png\")\n</code></pre> <p>Using the command line interface:</p> <pre><code>llama-canvas generate \"A mystical forest with glowing mushrooms and fairy lights\" \\\n    --agent stable_diffusion \\\n    --model runwayml/stable-diffusion-v1-5 \\\n    --width 512 \\\n    --height 512 \\\n    --params '{\"num_inference_steps\": 50, \"guidance_scale\": 7.5, \"negative_prompt\": \"blurry, low quality, distorted\"}' \\\n    --output mystical_forest.png\n</code></pre>"},{"location":"user_guide/image_generation/#advanced-prompt-engineering","title":"Advanced Prompt Engineering","text":"<p>Crafting effective prompts is a key skill for generating high-quality images. LlamaCanvas provides utilities to help with prompt engineering:</p> <pre><code>from llama_canvas.utils.prompts import enhance_prompt, analyze_prompt\n\n# Enhance a basic prompt with more details\nenhanced_prompt = enhance_prompt(\n    \"A cat in a garden\",\n    style=\"photorealistic\",\n    detail_level=\"high\",\n    aspect=\"wide angle\"\n)\nprint(enhanced_prompt)\n# Output: \"A photorealistic high-detail wide angle shot of a cat in a garden, \n#          with fine fur details, natural lighting, and vibrant colors.\"\n\n# Analyze a prompt for potential improvements\nanalysis = analyze_prompt(\"robot\")\nprint(analysis)\n# Output: {\n#   \"specificity\": \"low\",\n#   \"suggestions\": [\"Add details about the robot's appearance\", \n#                  \"Specify the environment\", \n#                  \"Add information about lighting and atmosphere\"]\n# }\n</code></pre>"},{"location":"user_guide/image_generation/#batch-generation","title":"Batch Generation","text":"<p>For generating multiple variations or a series of related images:</p> <pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas()\n\n# Generate multiple variations of the same prompt\nvariations = canvas.generate_variations(\n    prompt=\"A serene landscape with mountains\",\n    count=4,\n    variation_strength=0.3\n)\n\n# Save all variations\nfor i, image in enumerate(variations):\n    image.save(f\"landscape_variation_{i}.png\")\n\n# Generate a series of related images\nprompts = [\n    \"A forest at dawn\",\n    \"A forest at midday\",\n    \"A forest at sunset\",\n    \"A forest at night\"\n]\n\nseries = canvas.generate_batch(prompts)\n\n# Save the series\nfor i, image in enumerate(series):\n    image.save(f\"forest_{i}.png\")\n</code></pre>"},{"location":"user_guide/image_generation/#image-to-image-generation","title":"Image-to-Image Generation","text":"<p>LlamaCanvas also supports generating images based on existing images:</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\ninput_image = Image.load(\"input.png\")\n\n# Generate a new image based on the input image\noutput_image = canvas.generate_from_image(\n    image=input_image,\n    prompt=\"Convert this into a watercolor painting\",\n    strength=0.7  # How much to preserve of the original image (0-1)\n)\n\noutput_image.save(\"watercolor_version.png\")\n</code></pre> <p>Using the command line interface:</p> <pre><code>llama-canvas img2img input.png \"Convert this into a watercolor painting\" \\\n    --strength 0.7 \\\n    --output watercolor_version.png\n</code></pre>"},{"location":"user_guide/image_generation/#inpainting-and-outpainting","title":"Inpainting and Outpainting","text":"<p>LlamaCanvas supports inpainting (filling in parts of an image) and outpainting (extending an image beyond its original boundaries):</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\nbase_image = Image.load(\"portrait.png\")\n\n# Create a mask (white areas will be repainted)\nmask = Image.create_mask(\n    width=base_image.width,\n    height=base_image.height\n)\nmask.draw_rectangle(x=100, y=50, width=200, height=300, color=\"white\")\n\n# Inpaint the masked area\ninpainted = canvas.inpaint(\n    image=base_image,\n    mask=mask,\n    prompt=\"A beautiful flower bouquet\"\n)\ninpainted.save(\"portrait_with_flowers.png\")\n\n# Outpaint to extend the image\noutpainted = canvas.outpaint(\n    image=base_image,\n    direction=\"right\",\n    extend_by=256,\n    prompt=\"Continue the scene with a beach and ocean\"\n)\noutpainted.save(\"portrait_extended.png\")\n</code></pre>"},{"location":"user_guide/image_generation/#using-templates-and-references","title":"Using Templates and References","text":"<p>For more controlled generation, you can use templates and reference images:</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\ncanvas = Canvas()\n\n# Generate with a reference image for style\nreference = Image.load(\"reference_style.png\")\nstyled_image = canvas.generate_from_text(\n    prompt=\"A castle on a hill\",\n    reference_image=reference,\n    reference_mode=\"style\"  # Use the reference for style only\n)\nstyled_image.save(\"castle_styled.png\")\n\n# Use a template (image with a transparent area to fill)\ntemplate = Image.load(\"frame_template.png\")\nfilled_template = canvas.fill_template(\n    template=template,\n    prompt=\"A portrait of a young woman with flowers in her hair\"\n)\nfilled_template.save(\"portrait_in_frame.png\")\n</code></pre>"},{"location":"user_guide/image_generation/#controlling-generation-parameters","title":"Controlling Generation Parameters","text":"<p>LlamaCanvas allows fine-grained control over the generation process:</p> <pre><code>from llama_canvas.core.canvas import Canvas\n\ncanvas = Canvas()\n\n# Generate with specific parameters\nimage = canvas.generate_from_text(\n    prompt=\"A surreal landscape with floating islands\",\n    width=768,\n    height=512,\n    params={\n        # Claude parameters\n        \"temperature\": 0.7,\n        \"max_tokens\": 4000,\n\n        # Stable Diffusion parameters\n        \"num_inference_steps\": 75,\n        \"guidance_scale\": 8.5,\n        \"scheduler\": \"DPMSolverMultistep\",\n        \"seed\": 42,  # For reproducible results\n        \"negative_prompt\": \"blurry, distorted, low quality, ugly\"\n    }\n)\nimage.save(\"surreal_landscape.png\")\n</code></pre>"},{"location":"user_guide/image_generation/#managing-generation-results","title":"Managing Generation Results","text":"<p>LlamaCanvas provides utilities for managing and organizing generated images:</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.utils.gallery import Gallery\n\n# Create a gallery to manage generated images\ngallery = Gallery(\"my_generations\")\n\n# Generate and store images\ncanvas = Canvas()\n\nfor prompt in [\"mountain landscape\", \"ocean sunset\", \"forest path\"]:\n    image = canvas.generate_from_text(prompt)\n\n    # Add to gallery with metadata\n    gallery.add(\n        image,\n        metadata={\n            \"prompt\": prompt,\n            \"model\": \"claude-3-opus-20240229\",\n            \"date\": \"2024-05-01\"\n        }\n    )\n\n# Save the gallery\ngallery.save(\"my_gallery.json\")\n\n# Export all images\ngallery.export_all(\"output_folder\")\n\n# Search the gallery\nforest_images = gallery.search(\"forest\")\n</code></pre> <p>By mastering these image generation techniques, you can create a wide variety of visual content with LlamaCanvas. Experiment with different models, prompts, and parameters to achieve your desired results. </p>"},{"location":"user_guide/installation/","title":"Installation Guide","text":"<p>This guide will help you install LlamaCanvas and set up your environment.</p>"},{"location":"user_guide/installation/#requirements","title":"Requirements","text":"<p>LlamaCanvas requires the following:</p> <ul> <li>Python 3.8 or later</li> <li>pip (Python package installer)</li> <li>For video processing: ffmpeg</li> <li>For GPU acceleration: CUDA-compatible GPU (optional)</li> </ul>"},{"location":"user_guide/installation/#basic-installation","title":"Basic Installation","text":"<p>The simplest way to install LlamaCanvas is with pip:</p> <pre><code>pip install llama-canvas\n</code></pre> <p>This will install the core functionality of LlamaCanvas without optional dependencies.</p>"},{"location":"user_guide/installation/#installation-with-options","title":"Installation with Options","text":"<p>LlamaCanvas offers several installation options for different use cases:</p>"},{"location":"user_guide/installation/#api-server","title":"API Server","text":"<p>To use the web UI and API server:</p> <pre><code>pip install llama-canvas[api]\n</code></pre>"},{"location":"user_guide/installation/#claude-integration","title":"Claude Integration","text":"<p>To use Anthropic's Claude for multi-modal capabilities:</p> <pre><code>pip install llama-canvas[claude]\n</code></pre>"},{"location":"user_guide/installation/#stable-diffusion-support","title":"Stable Diffusion Support","text":"<p>To use Stable Diffusion for image generation:</p> <pre><code>pip install llama-canvas[diffusion]\n</code></pre>"},{"location":"user_guide/installation/#video-processing","title":"Video Processing","text":"<p>To enable video creation and manipulation:</p> <pre><code>pip install llama-canvas[video]\n</code></pre>"},{"location":"user_guide/installation/#development-environment","title":"Development Environment","text":"<p>For development and contributing:</p> <pre><code>pip install llama-canvas[dev]\n</code></pre>"},{"location":"user_guide/installation/#documentation","title":"Documentation","text":"<p>For building documentation locally:</p> <pre><code>pip install llama-canvas[docs]\n</code></pre>"},{"location":"user_guide/installation/#full-installation","title":"Full Installation","text":"<p>To install all features and dependencies:</p> <pre><code>pip install llama-canvas[full]\n</code></pre>"},{"location":"user_guide/installation/#installation-from-source","title":"Installation from Source","text":"<p>To install from source:</p> <pre><code>git clone https://github.com/llamasearch/llamacanvas.git\ncd llamacanvas\npip install -e \".[full]\"\n</code></pre>"},{"location":"user_guide/installation/#verifying-installation","title":"Verifying Installation","text":"<p>To verify that LlamaCanvas is installed correctly:</p> <pre><code>python -c \"import llama_canvas; print(llama_canvas.__version__)\"\n</code></pre> <p>You should see the version number printed out.</p>"},{"location":"user_guide/installation/#configuration","title":"Configuration","text":"<p>After installation, you may want to set up your configuration. Create a file at <code>~/.llama_canvas/config.json</code>:</p> <pre><code>{\n  \"claude_api_key\": \"your-anthropic-api-key\",\n  \"default_claude_model\": \"claude-3-opus-20240229\",\n  \"default_image_width\": 512,\n  \"default_image_height\": 512\n}\n</code></pre> <p>Alternatively, you can set environment variables:</p> <pre><code>export CLAUDE_API_KEY=\"your-anthropic-api-key\"\nexport DEFAULT_CLAUDE_MODEL=\"claude-3-opus-20240229\"\n</code></pre> <p>See the Configuration Guide for more details.</p>"},{"location":"user_guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user_guide/installation/#common-issues","title":"Common Issues","text":""},{"location":"user_guide/installation/#missing-dependencies","title":"Missing dependencies","text":"<p>If you encounter errors about missing dependencies, try installing with the appropriate option:</p> <pre><code>pip install llama-canvas[full]\n</code></pre>"},{"location":"user_guide/installation/#api-key-not-found","title":"API key not found","text":"<p>If you get errors about missing API keys, make sure you've set them up in your configuration file or environment variables.</p>"},{"location":"user_guide/installation/#video-processing-issues","title":"Video processing issues","text":"<p>For video processing issues, ensure ffmpeg is installed and available in your PATH:</p> <pre><code># On Ubuntu/Debian\nsudo apt-get install ffmpeg\n\n# On macOS with Homebrew\nbrew install ffmpeg\n\n# On Windows with Chocolatey\nchoco install ffmpeg\n</code></pre>"},{"location":"user_guide/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues that aren't covered here:</p> <ol> <li>Check the GitHub Issues to see if the problem has been reported</li> <li>Search the GitHub Discussions for similar problems</li> <li>Open a new issue or discussion if needed </li> </ol>"},{"location":"user_guide/quickstart/","title":"Quick Start Guide","text":"<p>This guide provides a quick introduction to using LlamaCanvas for various AI-driven image and video tasks.</p>"},{"location":"user_guide/quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"user_guide/quickstart/#command-line-interface","title":"Command Line Interface","text":"<p>LlamaCanvas provides a simple command-line interface for common operations.</p>"},{"location":"user_guide/quickstart/#generate-an-image-from-text","title":"Generate an image from text:","text":"<pre><code>llama-canvas generate \"A serene landscape with mountains and a lake at sunset\" --output landscape.png\n</code></pre>"},{"location":"user_guide/quickstart/#apply-a-style-to-an-image","title":"Apply a style to an image:","text":"<pre><code>llama-canvas style input.png \"Van Gogh\" --output styled.png\n</code></pre>"},{"location":"user_guide/quickstart/#enhance-image-resolution","title":"Enhance image resolution:","text":"<pre><code>llama-canvas enhance input.png --scale 2 --output enhanced.png\n</code></pre>"},{"location":"user_guide/quickstart/#launch-the-web-ui","title":"Launch the web UI:","text":"<pre><code>llama-canvas ui --browse\n</code></pre>"},{"location":"user_guide/quickstart/#python-api","title":"Python API","text":"<p>For more complex tasks, you can use the Python API:</p>"},{"location":"user_guide/quickstart/#image-generation","title":"Image Generation","text":"<pre><code>from llama_canvas.core.canvas import Canvas\n\n# Create a canvas\ncanvas = Canvas(width=512, height=512)\n\n# Generate an image from text\nimage = canvas.generate_from_text(\n    \"A serene landscape with mountains and a lake at sunset\"\n)\n\n# Save the result\nimage.save(\"landscape.png\")\n</code></pre>"},{"location":"user_guide/quickstart/#style-transfer","title":"Style Transfer","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\n# Create a canvas\ncanvas = Canvas()\n\n# Load an image\noriginal = Image.load(\"input.png\")\n\n# Apply a style\nstyled = canvas.apply_style(original, \"Van Gogh\")\n\n# Save the result\nstyled.save(\"styled_output.png\")\n</code></pre>"},{"location":"user_guide/quickstart/#image-enhancement","title":"Image Enhancement","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\n\n# Create a canvas\ncanvas = Canvas()\n\n# Load an image\noriginal = Image.load(\"input.png\")\n\n# Enhance the image\nenhanced = canvas.enhance(original, scale=2, denoise=True)\n\n# Save the result\nenhanced.save(\"enhanced_output.png\")\n</code></pre>"},{"location":"user_guide/quickstart/#video-creation","title":"Video Creation","text":"<pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.video import Video\n\n# Create a canvas\ncanvas = Canvas()\n\n# Generate a video from a sequence of prompts\nprompts = [\n    \"A serene landscape with mountains at dawn\",\n    \"A serene landscape with mountains at noon\",\n    \"A serene landscape with mountains at sunset\",\n    \"A serene landscape with mountains at night\"\n]\n\n# Create video with transitions between images\nvideo = canvas.create_video_from_prompts(\n    prompts, \n    duration=10,\n    fps=30,\n    transition=\"fade\"\n)\n\n# Save the result\nvideo.save(\"landscape_timelapse.mp4\")\n</code></pre>"},{"location":"user_guide/quickstart/#using-the-web-ui","title":"Using the Web UI","text":"<p>LlamaCanvas includes a web UI for interactive use:</p> <ol> <li> <p>Start the server:    <pre><code>llama-canvas ui --browse\n</code></pre></p> </li> <li> <p>This will open a browser window to the UI (usually at http://localhost:8000)</p> </li> <li> <p>Use the interface to:</p> </li> <li>Generate images from text</li> <li>Apply styles to uploaded images</li> <li>Enhance images</li> <li>Create videos</li> <li>View your creation history</li> </ol>"},{"location":"user_guide/quickstart/#working-with-claude","title":"Working with Claude","text":"<p>If you have installed LlamaCanvas with Claude integration:</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.utils.claude import ClaudeAgent\n\n# Configure Claude\nclaude_agent = ClaudeAgent(api_key=\"your-api-key\", model=\"claude-3-opus-20240229\")\n\n# Create a canvas with Claude agent\ncanvas = Canvas(agent=claude_agent)\n\n# Generate an image with Claude\nimage = canvas.generate_from_text(\n    \"A robot artist painting a landscape with digital brushes\"\n)\n\n# Save the result\nimage.save(\"claude_generated.png\")\n</code></pre>"},{"location":"user_guide/quickstart/#creating-pipelines","title":"Creating Pipelines","text":"<p>LlamaCanvas allows you to chain operations into pipelines:</p> <pre><code>from llama_canvas.core.canvas import Canvas\nfrom llama_canvas.core.image import Image\nfrom llama_canvas.utils.pipeline import Pipeline\n\n# Create a canvas\ncanvas = Canvas()\n\n# Create a pipeline\npipeline = Pipeline(canvas)\n\n# Add operations to the pipeline\npipeline.add_operation(\"generate\", prompt=\"A mountain landscape\")\npipeline.add_operation(\"apply_style\", style=\"Van Gogh\")\npipeline.add_operation(\"enhance\", scale=1.5, denoise=True)\n\n# Execute the pipeline\nresult = pipeline.execute()\n\n# Save the result\nresult.save(\"pipeline_result.png\")\n</code></pre>"},{"location":"user_guide/quickstart/#next-steps","title":"Next Steps","text":"<p>For more detailed information, explore:</p> <ul> <li>Core Concepts - Learn about the fundamental concepts of LlamaCanvas</li> <li>Image Generation - Detailed guide on generating images</li> <li>Style Transfer - Learn about available styles and customization</li> <li>Image Enhancement - Advanced image enhancement techniques</li> <li>Video Processing - In-depth video creation and editing guide</li> <li>API Reference - Complete API documentation </li> </ul>"}]}